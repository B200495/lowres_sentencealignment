"""
Implementation of 'Sentence track F1-measure' from Seljan et al., 2008:

Seljan, S., Agić, Ž. and Tadić, M., 2008. Evaluating sentence alignment on Croatian-English parallel corpora. FASSBL6, p.101.

References Langlais et al., 1998:

Langlais, P., Simard, M. and Véronis, J., 1998. Methods and practical issues in evaluating alignment techniques. In COLING 1998 Volume 1: The 17th International Conference on Computational Linguistics.

MY NOTES:

I want to partially-reward partial overlaps. Closest I've found is the Croatian-English paper (Seljian et al.) which uses method from Langlais et al., 1998 (methods and practical issues in evaluating alignment techniques).

I think this method rewards with a whole point (1) if even partially correct. I don't think I want to do this - can I record scores in the tuple as well? If I have to split, only get 0.5 point?

METHOD:

Input: Alignment file generated by VecAlign

Modify filepaths before running.
"""
import pandas as pd
import re

####### CREATE TEST ALIGNMENT FILE CONTAINING RAW MANUAL ALIGNMENT TEXT (REMOVE OMITTED LINES)
####### CREATE MANUAL ALIGNMENT FILE (TUPLES OF LINE INDICES (SRC INDEX[ES], TARGET INDEX[ES])

### CONSTANTS ####

# specify whether bleualigned or vecaligned to specify how file should be parsed
bleuorvec = "vec"

# automatic alignment file path
# auto_alignmentpath = #ADD: e.g. f"./Bleualign/bleualignment_grumpy.txt"

auto_alignmentpath = #ADD: e.g. f"./vecalign/vecaligntest_src/alignment_files/aligned_01_raw.txt" # VECALIGN Many:many possibility
# auto_alignmentpath = #ADD: e.g. f"./Bleualign/bleualignment_bleualigntest.txt"

# reference alignment file path - alignments in format per line:
# 318,319,320 - 217,218
# ref_alignmentpath = #ADD: e.g. f"./dict_transl/latse7test_alignmentfile.txt"
ref_alignmentpath = #ADD: e.g. f"./dict_transl/latse7test_alignmentfile_modifiedindices.txt"


#### FUNCTIONS ####
# parse reference alignment file
def parse_reference(ref_filepath):
    """
    Read in and parse file so same formatting as auto-alignment file
    INPUT: Lines in input .txt file formatted like this:
    318,319,320 - 217,218
    OUTPUT: [([s1,s2],[t4],[REWARD=1]), ([s],[t],[REWARD])] - s and t in square brackets are original file line indices. LIST.
    """
    al_list = []
    with open(ref_filepath, 'r') as al_file:
        for line in al_file:
            parts = line.strip().split(' - ')
            source_sentences = parts[0].split(',')
            target_sentences = parts[1].split(',')

            # turn all indices in both SL and TL index lists into ints
            alignment = (tuple(map(int, source_sentences)),
                         tuple(map(int, target_sentences)),
                         (1,))

            al_list.append(alignment)

    return al_list


# parse bleualign alignment file output (function output should be same format as vecalign). NOTE BleuAlign referencing starts at 0 for EACH .EOA SECTION.
# OUTPUT [([s1,s2],[t4],[REWARD=1]), ([s],[t],[REWARD])] - s and t in square brackets are original file line indices. LIST.

def parse_blealigned(auto_filepath):
    """
    Read in and parse file so same formatting as ref-alignment file
    INPUT: Lines in input .txt file formatted like this:
    alignment: 318,319,320 - 217,218
    OUTPUT: [([s1,s2],[t4],[REWARD=1]), ([s],[t],[REWARD])] - s and t in square brackets are original file line indices. LIST.
    """
    al_list = []

    with open(auto_filepath, 'r') as al_file:
        for line in al_file:
            if line.startswith("alignment:"):
                line = line[11:]
                parts = line.strip().split(' - ')
                source_part = parts[0].split(',')
                target_part = parts[1].split(',')

                # Handle empty source part by replacing it with ('_',)
                if source_part:
                    source_sentences = tuple(map(int, source_part))

                # Handle empty target part by replacing it with ('_',)
                if target_part:
                    target_sentences = tuple(map(int, target_part))

                # Create the alignment tuple
                alignment = (source_sentences,  # No need to convert to tuple here, it's already handled
                         target_sentences,  # Convert to tuple
                         (1,))

                al_list.append(alignment)
            # elif "unaligned" in line: # cannot use this approach bc it only outlines failed 1:1 alignments
            #     match = re.search(r'(\d+):', line)
            #     if match:
            #         source_sentences = int(match.group(1))
            #         alignment = ((source_sentences,),
            #                  ('_',),
            #                  (1,))
            #         al_list.append(alignment)
            # Maximum source and target language integers

    return al_list
# parse vecalign alignment file (function output should be same format as bleualign)
# OUTPUT [([s1,s2],[t4],[REWARD=1]), ([s],[t],[REWARD])] - s and t in square brackets are original file line indices. LIST.

def append_unaligned_bleu(bleuauto_list):
    """
    Identify missing alignments which BLEU didn't mention but didn't align by iterating through all SL and TL digits and seeing what's missing. Input list. Output list.
    """
    ### DEAL WITH UNALIGNED

    max_source = 329
    max_target = 223

    # Create sets to store existing source and target language integers
    existing_source = set()
    existing_target = set()

    # Iterate through the source-target sets to populate the existing sets
    for source, target, _ in bleuauto_list:
        existing_source.update(source)
        existing_target.update(target)

    # Find missing source and target language integers
    missing_source = set(range(max_source)) - existing_source
    missing_target = set(range(max_target)) - existing_target

    print("Missing source language integers:", missing_source)
    print("Missing target language integers:", missing_target)

    # Create new tuples based on missing source and target integers
    new_tuples = []
    for source_int in missing_source:
        new_tuples.append(((source_int,), ('_',), (1,)))
    for target_int in missing_target:
        new_tuples.append((('_',), (target_int,), (1,)))

    # Update the original set with the new tuples
    al_list = set(bleuauto_list).union(new_tuples)
    print(al_list)

    return list(al_list)

def parse_vecaligned(auto_filepath):
    """
    Read in and parse file so same formatting as ref-alignment file
    INPUT: Lines in input .txt file formatted like this:
    [16, 17]:[7,8,9]:0.581982
    OUTPUT: [([s1,s2],[t4],[REWARD=1]), ([s],[t],[REWARD])] - s and t in square brackets are original file line indices. LIST.
    """
    al_list = []

    with open(auto_filepath, 'r') as al_file:
        for line in al_file:
            # Split the line into source and target sentences
            source_str, target_str, _ = line.split(':')

            # Convert the strings into tuples of integers for the source part
            source_sentences = tuple(int(idx) for idx in source_str.strip("[]").split(',') if idx.strip()) or ('_',)

            # Convert the strings into tuples of integers for the target part
            target_sentences = tuple(int(idx) for idx in target_str.strip("[]").split(',') if idx.strip()) or ('_',)


            # Create the alignment tuple
            alignment = (source_sentences,
                         target_sentences,
                         (1,))

            # Append the alignment tuple to the list of alignments
            al_list.append(alignment)

    return al_list

def retrieve_part(alignment_tuple, src_tgt_reward):
    """
    INPUT: Single alignment tuple ((src_indices),(tgt_indices),(reward)). 'src' or 'tgt' or 'reward' depending on which part of the tuple you want to retrieve.
    OUTPUT: Just the chosen index tuple
    """
    if src_tgt_reward == "src":
        part = alignment_tuple[0]
    elif src_tgt_reward == "tgt":
        part = alignment_tuple[1]
    elif src_tgt_reward == "reward":
        part = alignment_tuple[2]

    return part

def make_onetoone(alignment_set):
    """
    INPUT: Either automatic of system alignment set potentially including many:many, 1:many, many:1 alignments. DISCARD NULLS TO IMPLEMENT 1997 PAPER.
    OUTPUT: Alignment set so that alignments including > 1 indices on src or tgt side are enumerated to all poss 1:1 mappings.
    """
    new_alignments = []
    for alignment in alignment_set:
        src_indices = retrieve_part(alignment, "src")
        tgt_indices = retrieve_part(alignment, "tgt")
        if len(src_indices) > 1 or len(tgt_indices) > 1:
            # if '_' not in src_indices:
            #     src_indices += ('_',)
            # if '_' not in tgt_indices:
            #     tgt_indices += ('_',)
            for src_index in src_indices:
                for tgt_index in tgt_indices:
                    alignment = ((src_index,), (tgt_index,), (1,))
                    new_alignments.append(alignment)
        else:
            new_alignments.append(alignment)

    ## discard null entries

    filtered_alignments = set()

    for source, target, score in new_alignments:
        if '_' not in source and '_' not in target:
            filtered_alignments.add((source, target, score))

    return filtered_alignments
    # return new_alignments

# Enumerate many:1, 1:many and many:many sets - rescore (1 --> 0.5)

def make_onetoone_rescore(alignment_set):
    """
    INPUT: Either automatic of system alignment set potentially including many:many, 1:many, many:1 alignments.
    OUTPUT: Alignment set so that alignments including > 1 indices on src or tgt side are enumerated to all poss 1:1 mappings.
    """
    new_alignments = []
    for alignment in alignment_set:
        src_indices = retrieve_part(alignment, "src")
        tgt_indices = retrieve_part(alignment, "tgt")
        if len(src_indices) > 1 or len(tgt_indices) > 1:
            # if '_' not in src_indices:
            #     src_indices += ('_',)
            # if '_' not in tgt_indices:
            #     tgt_indices += ('_',)
            total_enumerations = 0
            for src_index in src_indices:
                for tgt_index in tgt_indices:
                    total_enumerations += 1
            reward = 1/total_enumerations
            for src_index in src_indices:
                for tgt_index in tgt_indices:
                    alignment = ((src_index,), (tgt_index,), (reward,))
                    new_alignments.append(alignment)
        else:
            new_alignments.append(alignment)
    return new_alignments

def countscores(alignment_set):
    total_sum = 0
    for inner_tuple in alignment_set:
            total_sum += inner_tuple[2][0]
    return total_sum

#### CODE ####

results_list = []

# REF ALIGNMENT FILE: read in and format alignment outputs to enumerate split alignment types and alter reward score (1 --> 0.5)

ref_alignment = parse_reference(ref_alignmentpath)

# AUTO ALIGNMENT FILE: read in and parse alignment file depending on whether bleualign or vecalign. Format alignment outputs to enumerate split alignment types and alter reward score (1 --> 0.5)

if bleuorvec == "bleu":
    auto_alignment = parse_blealigned(auto_alignmentpath)
    auto_alignment = append_unaligned_bleu(auto_alignment)
else:
    try:
        auto_alignment = parse_vecaligned(auto_alignmentpath)
        auto_alignment = append_unaligned_bleu(auto_alignment)
    except:
        print("Auto-alignment file not in expected format")

#### NORMAL P, R, F1 ####

# Compute NORMAL precision: auto INTERSECT ref / auto
ref_alignment = set(ref_alignment)
auto_alignment = set(auto_alignment)

# filtered_alignments = set()

# for source, target, score in auto_alignment:
#     if '_' not in source and '_' not in target:
#         filtered_alignments.add((source, target, score))
# auto_alignment = filtered_alignments

alignment_intersect = ref_alignment.intersection(auto_alignment)

normal_precision = (len(alignment_intersect) / len(auto_alignment))
print(f"NORMAL PRECISION: {normal_precision}")
print(f"NORMAL PRECISION: {len(alignment_intersect)} div {len(auto_alignment)}")

# Compute NORMAL recall: auto INTERSECT ref / ref

normal_recall = (len(alignment_intersect) / len(ref_alignment))
print(f"NORMAL RECALL: {normal_recall}")
print(f"NORMAL RECALL: {len(alignment_intersect)} div {len(ref_alignment)}")

# Compute NORMAL F1: 2 * ((recall*precision)/(recall+precision))
f1_top = normal_recall * normal_precision
f1_bottom = normal_recall + normal_precision
normal_f1 = 2 * (f1_top/f1_bottom)

print(f"NORMAL F1: {normal_f1}")

results_list.append({
    'Method': 'Normal',
    'Precision': normal_precision,
    'Recall': normal_recall,
    'F1': normal_f1
})

#### REWARD PARTIAL: P, R, F1 ####

expanded_auto_alignment = make_onetoone(auto_alignment)
expanded_ref_alignment = make_onetoone(ref_alignment)

# Compute PARTIAL REWARD precision: auto INTERSECT ref / auto
expanded_ref_alignment = set(expanded_ref_alignment)
expanded_auto_alignment = set(expanded_auto_alignment)
alignment_intersect = expanded_ref_alignment.intersection(expanded_auto_alignment)

partialreward_precision = (len(alignment_intersect) / len(expanded_auto_alignment))
print(f"PARTIAL REWARD PRECISION: {partialreward_precision}")
print(f"PARTIAL REWARD PRECISION: {len(alignment_intersect)} div {len(expanded_auto_alignment)}")

# Compute PARTIAL REWARD recall: auto INTERSECT ref / ref

partialreward_recall = (len(alignment_intersect) / len(expanded_ref_alignment))
print(f"PARTIAL REWARD RECALL: {partialreward_recall}")
print(f"PARTIAL REWARD RECALL: {len(alignment_intersect)} div {len(expanded_ref_alignment)}")

# Compute PARTIAL REWARD F1: 2 * ((recall*precision)/(recall+precision))
f1_top = partialreward_recall * partialreward_precision
f1_bottom = partialreward_recall + partialreward_precision
partialreward_f1 = 2 * (f1_top/f1_bottom)

print(f"PARTIAL REWARD F1: {partialreward_f1}")


results_list.append({
    'Method': 'Partial Reward',
    'Precision': partialreward_precision,
    'Recall': partialreward_recall,
    'F1': partialreward_f1
})
#### PARTIALLY REWARD PARTIAL: P, R, F1 ####

rescored_auto_alignment = make_onetoone_rescore(auto_alignment)
rescored_ref_alignment = make_onetoone_rescore(ref_alignment)

# Compute PARTIAL REWARD precision: auto INTERSECT ref / auto
rescored_ref_alignment = set(rescored_ref_alignment)
rescored_auto_alignment = set(rescored_auto_alignment)

# Extract the first two tuples from each tuple in the sets
auto_first_two = {(tup[0], tup[1]) for tup in rescored_auto_alignment}
ref_first_two = {(tup[0], tup[1]) for tup in rescored_ref_alignment}

# Find the intersection based on the first two elements
intersection_first_two = auto_first_two.intersection(ref_first_two)

alignment_intersect2 = []
for tup_first_two in intersection_first_two:
    min_value = min(other_tup[2] for other_tup in rescored_ref_alignment | rescored_auto_alignment if (other_tup[0], other_tup[1]) == tup_first_two)
    alignment_intersect2.append((tup_first_two[0], tup_first_two[1], min_value))

alignment_intersect2 = set(alignment_intersect2)
# alignment_intersect = rescored_ref_alignment.intersection(rescored_auto_alignment)

intersect_score = countscores(alignment_intersect2)
auto_al_score = countscores(rescored_auto_alignment)
ref_al_score = countscores(rescored_ref_alignment)

partialpartialreward_precision = (intersect_score / auto_al_score)
print(f"PARTIAL PARTIAL REWARD PRECISION: {partialpartialreward_precision}")
print(f"PARTIAL PARTIAL REWARD PRECISION: {intersect_score} div {auto_al_score}")

# Compute recall: |A_s INTERSECT A_r | / |A_r|

partialpartialreward_recall = (intersect_score / ref_al_score)
print(f"PARTIAL PARTIAL REWARD RECALL: {partialpartialreward_recall}")
print(f"PARTIAL PARTIAL REWARD PRECISION: {intersect_score} div {ref_al_score}")

# Compute F1: 2 * ( (recall * precision) / (recall + precision) )

f1_top = partialpartialreward_recall * partialpartialreward_precision
f1_bottom = partialpartialreward_recall + partialpartialreward_precision
partialpartialreward_f1 = 2 * (f1_top/f1_bottom)

print(f"PARTIAL REWARD F1: {partialpartialreward_f1}")

results_list.append({
    'Method': 'Partially Reward Partial',
    'Precision': partialpartialreward_precision,
    'Recall': partialpartialreward_recall,
    'F1': partialpartialreward_f1
})

# print results

# Create a dataframe from the results_list
df = pd.DataFrame(results_list)

# Print the dataframe
print(df)


#### Precision - out of auto-alignment bisegments, how many alignments were correct?

#### Recall - out of ref-alignment bisegments, how many did the auto-aligner correctly retrieve?

### No ref-alignments have null/blank indices. Only auto-alignments have null/blank indices.
